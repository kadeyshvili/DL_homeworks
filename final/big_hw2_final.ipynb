{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-05T12:13:14.856596Z","iopub.status.busy":"2024-03-05T12:13:14.856143Z","iopub.status.idle":"2024-03-05T12:13:14.863680Z","shell.execute_reply":"2024-03-05T12:13:14.862708Z","shell.execute_reply.started":"2024-03-05T12:13:14.856560Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","from torch import Tensor\n","from torch.nn import Transformer\n","import math\n","import numpy as np\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{},"source":["### Решение вдохновлено https://pytorch.org/tutorials/beginner/translation_transformer.html"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","Path('/kaggle/working/model').mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["seed = 42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SRC_LANGUAGE = 'de'\n","TRGT_LANGUAGE = 'en'\n","token_transform = {}\n","token_transform[SRC_LANGUAGE] = get_tokenizer(None, language='de_core_web_sm')\n","token_transform[TRGT_LANGUAGE] = get_tokenizer(None, language='en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TranslationDataset(Dataset):\n","    def __init__(self, source, target, data_type = 'train'):\n","        self.type = data_type\n","        self.source_lines = None\n","        with open(source, 'r') as file:\n","            self.source_lines = file.readlines()\n","        if self.type != 'test': \n","            self.taret_lines = None\n","            with open(target, 'r') as file:\n","                self.taret_lines = file.readlines()\n","\n","        \n","    def __len__(self):\n","        return len(self.source_lines)\n","    \n","    def __getitem__(self, idx):\n","        if self.type != 'test':\n","            return (self.source_lines[idx], self.taret_lines[idx])\n","        else:\n","            return self.source_lines[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = TranslationDataset(\"/kaggle/input/bhw2-data2/train.de-en.de\", \"/kaggle/input/bhw2-data2/train.de-en.en\")\n","valid_dataset = TranslationDataset(\"/kaggle/input/bhw2-data2/val.de-en.de\", \"/kaggle/input/bhw2-data2/val.de-en.en\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def yield_tokens(data_iter, language):\n","    language_index = {SRC_LANGUAGE: 0, TRGT_LANGUAGE: 1}\n","    for data_sample in data_iter:\n","        yield token_transform[language](data_sample[language_index[language]])\n","\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","\n","vocab_transform = {}\n","for ln in [SRC_LANGUAGE, TRGT_LANGUAGE]:\n","    tokens = yield_tokens(train_dataset, ln)\n","    vocab_transform[ln] = build_vocab_from_iterator(\n","        tokens,\n","        min_freq=1,\n","        specials=special_symbols,\n","        special_first=True,\n","    )\n","\n","for ln in [SRC_LANGUAGE, TRGT_LANGUAGE]:\n","    vocab_transform[ln].set_default_index(UNK_IDX)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","def tensor_transform(token_ids):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TRGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln], \n","                                               vocab_transform[ln], \n","                                               tensor_transform) \n","\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TRGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n","    return src_batch, tgt_batch\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","    \n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n","    \n","    src_padding_mask = (src == PAD_IDX)\n","    tgt_padding_mask = (tgt == PAD_IDX)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","        \n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1)]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Seq2SeqTransformer(nn.Module):\n","    def __init__(\n","        self,\n","        num_encoder_layers: int,\n","        num_decoder_layers: int,\n","        emb_size: int,\n","        nhead: int,\n","        src_vocab_size: int,\n","        tgt_vocab_size: int,\n","        dim_feedforward: int = 512,\n","        dropout: float = 0.1\n","    ):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(\n","            d_model=emb_size,\n","            nhead=nhead,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","            batch_first=True\n","        )\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def save_model(model, optimizer, scheduler = None, PATH = \"/kaggle/working/model/checkpoint.pth\"):\n","    torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict' : scheduler.state_dict() if scheduler else {},\n","            }, PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, criterion, val_loader, tqdm_desc):\n","    model.eval()\n","    losses = 0\n","    for src, tgt in tqdm(val_loader, total=len(list(val_loader)), desc= tqdm_desc):\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","    \n","        tgt_input = tgt[:, :-1]\n","        \n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        \n","        logits = model(\n","            src, \n","            tgt_input, \n","            src_mask, \n","            tgt_mask,\n","            src_padding_mask, \n","            tgt_padding_mask, \n","            src_padding_mask\n","        )\n","        tgt_out = tgt[:, 1:]\n","        loss = criterion(logits.view(-1, tgt_vocab_size), tgt_out.contiguous().view(-1))\n","        losses += loss.item()\n","        torch.cuda.empty_cache()\n","    return losses / len(list(val_loader))\n","\n","\n","def train_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n","    model.train()\n","    losses = 0\n","    for src, tgt in tqdm(train_loader, total=len(list(train_loader)), desc = tqdm_desc):            \n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","        \n","        tgt_input = tgt[:, :-1]\n","        \n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","        logits = model(\n","            src, \n","            tgt_input, \n","            src_mask, \n","            tgt_mask,\n","            src_padding_mask, \n","            tgt_padding_mask, \n","            src_padding_mask\n","        )\n","        optimizer.zero_grad()\n","        tgt_out = tgt[:, 1:]\n","        loss = criterion(logits.view(-1, tgt_vocab_size), tgt_out.contiguous().view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        losses += loss.item()\n","        torch.cuda.empty_cache()\n","    return losses / len(list(train_loader))\n","    \n","\n","\n","def train(model, optimizer, criterion, scheduler, train_loader, val_loader, n_epochs):\n","    train_loss = 0.0\n","    val_loss = 0.0\n","    best_val_loss = 1e8\n","    for epoch in range(n_epochs):\n","        train_loss = train_epoch(model, optimizer, criterion, train_loader,  f'Training epoch {epoch + 1}/{n_epochs}')\n","        val_loss = evaluate(model, criterion, val_loader, f'Validating epoch {epoch + 1}/{n_epochs}')\n","        print(f\"Epoch {epoch + 1}\")\n","        print(f\" train loss: {train_loss}\")\n","        print(f\" val loss: {val_loss}\\n\")\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            save_model(model, optimizer, scheduler, PATH = \"/kaggle/working/model/best_model.pth\")\n","            print('Saved better model')\n","        wandb.log({'train_loss': train_loss, 'val_loss': val_loss})\n","        if scheduler is not None:\n","            scheduler.step(val_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_model(model, optimizer, scheduler = None, PATH = \"/kaggle/working/model/checkpoint.pth\"):\n","    checkpoint = torch.load(PATH)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    if scheduler:\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","    return model, optimizer, scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["src_vocab_size = len(vocab_transform[SRC_LANGUAGE])\n","tgt_vocab_size = len(vocab_transform[TRGT_LANGUAGE])\n","emb_size = 1024\n","num_head = 8\n","hidden_dim = 1024\n","batch_size = 128\n","num_enc_layers = 3\n","num_dec_layers = 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","val_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","\n","run = wandb.init(project=\"bhw2\", entity = \"polina-kadeyshvili\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Seq2SeqTransformer(\n","    num_enc_layers, \n","    num_dec_layers, \n","    emb_size,\n","    num_head, \n","    src_vocab_size, \n","    tgt_vocab_size, \n","    hidden_dim\n",").to(device)\n","\n","for p in model.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_epochs = 15\n","\n","\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing = 0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-05T12:14:08.437490Z","iopub.status.busy":"2024-03-05T12:14:08.437143Z","iopub.status.idle":"2024-03-05T12:14:09.380642Z","shell.execute_reply":"2024-03-05T12:14:09.379639Z","shell.execute_reply.started":"2024-03-05T12:14:08.437450Z"},"trusted":true},"outputs":[],"source":["train(model, optimizer, criterion, scheduler, train_dataloader, val_dataloader, n_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-05T12:14:09.382180Z","iopub.status.busy":"2024-03-05T12:14:09.381856Z","iopub.status.idle":"2024-03-05T12:14:09.406274Z","shell.execute_reply":"2024-03-05T12:14:09.405349Z","shell.execute_reply.started":"2024-03-05T12:14:09.382150Z"},"trusted":true},"outputs":[],"source":["wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loaded_model = torch.load('/kaggle/working/model/best_model.pth')\n","best_model = Seq2SeqTransformer(\n","    num_enc_layers, \n","    num_dec_layers, \n","    emb_size,\n","    num_head, \n","    src_vocab_size, \n","    tgt_vocab_size, \n","    hidden_dim\n",").to(device)\n","best_model.load_state_dict(loaded_model['model_state_dict'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def beam_search_decode(model, src, src_mask, max_len, start_symbol, beam_size):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    \n","    beam = [(ys, 0)]\n","    \n","    for i in range(max_len-1):\n","        candidates = []\n","        \n","        for ys, score in beam:\n","            memory = memory.to(device)\n","            if i == 0:\n","                ys = ys.transpose(1, 0)\n","            tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n","                        .type(torch.bool)).to(device)\n","            out = model.decode(ys, memory, tgt_mask)\n","            out = out\n","            prob = model.generator(out[:, -1])\n","            _, topi = torch.topk(prob, beam_size)\n","            \n","            for k in range(beam_size):\n","                next_word = topi[0][k].item()\n","                new_ys = torch.cat([ys,\n","                                    torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","                candidates.append((new_ys, score + torch.log(prob[0][next_word]).item()))\n","        \n","        candidates.sort(key=lambda x: x[1], reverse=True)\n","        \n","        beam = candidates[:beam_size]\n","        \n","        done = True\n","        for ys, score in beam:\n","            if ys[0][-1].item() != EOS_IDX:\n","                done = False\n","                break\n","        if done:\n","            break\n","    \n","    beam.sort(key=lambda x: x[1], reverse=True)\n","    \n","    return beam[0][0]\n","\n","def translate_beam_search(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)\n","    num_tokens = src.shape[1]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = beam_search_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, beam_size=5).flatten()\n","    return \" \".join(vocab_transform[TRGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        if i == 0:\n","            ys = ys.transpose(1, 0)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(1))\n","                    .type(torch.bool)).to(device)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()    \n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(1, -1)\n","    num_tokens = src.shape[1]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TRGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_data = TranslationDataset('/kaggle/input/bhw2-data2/test1.de-en.de', None, data_type = 'test')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('results.txt', 'w') as f:\n","    for sentence in test_data:\n","        res = translate(best_model, sentence)\n","        res += '\\n'\n","        f.write(res)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4550489,"sourceId":7776875,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
